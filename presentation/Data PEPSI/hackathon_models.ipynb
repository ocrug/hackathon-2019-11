{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hackathon_models.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJ41Kp2J4MIL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "c706bf6e-220d-4f20-d465-e0d1d9bd3f88"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "#from sklearn.linear_model import LogisticRegression\n",
        "from random import seed\n",
        "\n",
        "data_set = pd.read_csv('/content/sample_data/new_bank.csv',sep=\",\")\n",
        "#print(data_set)\n",
        "'''\n",
        "for a in range(len(data_set['y'])):\n",
        "  if data_set['y'][a] == \"yes\":\n",
        "    data_set['y'][a] = 1\n",
        "  else:\n",
        "    data_set['y'][a] = 0\n",
        "dummy_y = data_set.pop('y')\n",
        "data_set.insert(39,'new_y',dummy_y)\n",
        "#data_set.drop(index = [0], axis = 1)\n",
        "data_set = data_set.loc[:, ~data_set.columns.str.contains('^Unnamed')]\n",
        "#data = pd.concat([data_set,dummy_y], axis=1)\n",
        "#data.drop(data.columns[7], axis = 1, inplace = True)\n",
        "'''\n",
        "#data_set = data_set[['duration', 'day', 'balance', 'age', 'poutcome_success', 'campaign', 'pdays', 'housing_1', 'poutcome_unknown', 'previous', 'y_1']]\n",
        "print(data_set)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       age  balance  day  duration  ...  default_1  housing_1  loan_1  y_1\n",
            "0       58     2143    5       261  ...          0          1       0    0\n",
            "1       44       29    5       151  ...          0          1       0    0\n",
            "2       33        2    5        76  ...          0          1       1    0\n",
            "3       47     1506    5        92  ...          0          1       0    0\n",
            "4       33        1    5       198  ...          0          0       0    0\n",
            "...    ...      ...  ...       ...  ...        ...        ...     ...  ...\n",
            "45206   51      825   17       977  ...          0          0       0    1\n",
            "45207   71     1729   17       456  ...          0          0       0    1\n",
            "45208   72     5715   17      1127  ...          0          0       0    1\n",
            "45209   57      668   17       508  ...          0          0       0    0\n",
            "45210   37     2971   17       361  ...          0          0       0    0\n",
            "\n",
            "[45211 rows x 49 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQu6o2sx4x2C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.combine import SMOTEENN\n",
        "from collections import Counter\n",
        "data_y = data_set.iloc[:,48]\n",
        "data_x = data_set.iloc[:,:48]\n",
        "#smo = SMOTE(random_state = 42)\n",
        "#data_x, data_y = smo.fit_sample(data_x, data_y)\n",
        "#print(Counter(data_y))\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=.1)\n",
        "#smo = SMOTE(random_state = 42)\n",
        "#x_train, y_train = smo.fit_sample(x_train, y_train)\n",
        "smote_enn = SMOTEENN(sampling_strategy='minority',random_state=100)\n",
        "x_train, y_train = smote_enn.fit_resample(x_train, y_train)\n",
        "#print(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZeQ6lcO26Bv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def fitting(classifier):\n",
        "  seed(100)\n",
        "  #classifier = LogisticRegression(C = 1e5)\n",
        "  classifier.fit(x_train, y_train.astype('int'))\n",
        "  result = classifier.predict(x_test)\n",
        "  print('result：', result) \n",
        "  score = classifier.score(x_test, y_test.astype('int'), sample_weight=None)\n",
        "  print('score: ', score)\n",
        "  print(classification_report(y_test.tolist(), result.tolist()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASb5IYvE5tLX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "06c80d06-f581-4f9f-a7ee-ad1db8ba8247"
      },
      "source": [
        "#sleep(1)\n",
        "print('Logistic Regression:')\n",
        "LR_clf = LogisticRegression(C = 1e5)\n",
        "fitting(LR_clf)\n",
        "print('-------------------------------------------------------')\n",
        "print('Decision Tree:')\n",
        "DT_clf = DecisionTreeClassifier()\n",
        "fitting(DT_clf)\n",
        "print('-------------------------------------------------------')\n",
        "'''\n",
        "print('Linear Regression:')\n",
        "LR_clf = LinearRegression()\n",
        "fitting(LR_clf)\n",
        "print('-------------------------------------------------------')\n",
        "'''\n",
        "print('KNN:')\n",
        "KNN_clf = KNeighborsClassifier()\n",
        "fitting(KNN_clf)\n",
        "print('-------------------------------------------------------')\n",
        "print('Random Forest:')\n",
        "RF_clf = RandomForestClassifier(n_estimators = 200)\n",
        "fitting(RF_clf)\n",
        "print('-------------------------------------------------------')\n",
        "print('Adaboost:')\n",
        "ADB_clf = AdaBoostClassifier(n_estimators = 200)\n",
        "fitting(ADB_clf)\n",
        "print('-------------------------------------------------------')\n",
        "print('Bagging:')\n",
        "B_clf = BaggingClassifier(n_estimators = 200)\n",
        "fitting(B_clf)\n",
        "print('-------------------------------------------------------')\n",
        "print('GrandientBoosting:')\n",
        "GB_clf = GradientBoostingClassifier(n_estimators = 200)\n",
        "fitting(GB_clf)\n",
        "print('-------------------------------------------------------')\n",
        "print('BernoulliNB:')\n",
        "BNB_clf = BernoulliNB()\n",
        "fitting(BNB_clf)\n",
        "print('-------------------------------------------------------')\n",
        "print('GaussianNB:')\n",
        "GNB_clf = GaussianNB()\n",
        "fitting(GNB_clf)\n",
        "print('-------------------------------------------------------')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic Regression:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "result： [0 0 0 ... 0 0 0]\n",
            "score:  0.9022556390977443\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95      3988\n",
            "           1       0.67      0.34      0.45       534\n",
            "\n",
            "    accuracy                           0.90      4522\n",
            "   macro avg       0.79      0.66      0.70      4522\n",
            "weighted avg       0.89      0.90      0.89      4522\n",
            "\n",
            "-------------------------------------------------------\n",
            "Decision Tree:\n",
            "result： [0 0 0 ... 0 0 0]\n",
            "score:  0.8759398496240601\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93      3988\n",
            "           1       0.47      0.47      0.47       534\n",
            "\n",
            "    accuracy                           0.88      4522\n",
            "   macro avg       0.70      0.70      0.70      4522\n",
            "weighted avg       0.88      0.88      0.88      4522\n",
            "\n",
            "-------------------------------------------------------\n",
            "KNN:\n",
            "result： [0 0 0 ... 0 0 0]\n",
            "score:  0.8794781070322866\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.96      0.93      3988\n",
            "           1       0.48      0.25      0.33       534\n",
            "\n",
            "    accuracy                           0.88      4522\n",
            "   macro avg       0.69      0.61      0.63      4522\n",
            "weighted avg       0.86      0.88      0.86      4522\n",
            "\n",
            "-------------------------------------------------------\n",
            "Random Forest:\n",
            "result： [0 0 0 ... 0 0 0]\n",
            "score:  0.8998230871295887\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.94      3988\n",
            "           1       0.63      0.37      0.46       534\n",
            "\n",
            "    accuracy                           0.90      4522\n",
            "   macro avg       0.78      0.67      0.70      4522\n",
            "weighted avg       0.89      0.90      0.89      4522\n",
            "\n",
            "-------------------------------------------------------\n",
            "Adaboost:\n",
            "result： [0 0 0 ... 0 0 0]\n",
            "score:  0.8954002653693056\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.94      3988\n",
            "           1       0.60      0.35      0.44       534\n",
            "\n",
            "    accuracy                           0.90      4522\n",
            "   macro avg       0.76      0.66      0.69      4522\n",
            "weighted avg       0.88      0.90      0.88      4522\n",
            "\n",
            "-------------------------------------------------------\n",
            "Bagging:\n",
            "result： [0 0 0 ... 0 0 0]\n",
            "score:  0.9042459088898718\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.96      0.95      3988\n",
            "           1       0.63      0.47      0.54       534\n",
            "\n",
            "    accuracy                           0.90      4522\n",
            "   macro avg       0.78      0.72      0.74      4522\n",
            "weighted avg       0.90      0.90      0.90      4522\n",
            "\n",
            "-------------------------------------------------------\n",
            "GrandientBoosting:\n",
            "result： [0 0 0 ... 0 0 0]\n",
            "score:  0.9068996019460416\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.97      0.95      3988\n",
            "           1       0.67      0.42      0.51       534\n",
            "\n",
            "    accuracy                           0.91      4522\n",
            "   macro avg       0.80      0.69      0.73      4522\n",
            "weighted avg       0.90      0.91      0.90      4522\n",
            "\n",
            "-------------------------------------------------------\n",
            "BernoulliNB:\n",
            "result： [1 0 0 ... 0 0 0]\n",
            "score:  0.8310482087571871\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.89      0.90      3988\n",
            "           1       0.32      0.37      0.34       534\n",
            "\n",
            "    accuracy                           0.83      4522\n",
            "   macro avg       0.62      0.63      0.62      4522\n",
            "weighted avg       0.84      0.83      0.84      4522\n",
            "\n",
            "-------------------------------------------------------\n",
            "GaussianNB:\n",
            "result： [0 0 0 ... 0 0 0]\n",
            "score:  0.8580274214949137\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.90      0.92      3988\n",
            "           1       0.42      0.53      0.47       534\n",
            "\n",
            "    accuracy                           0.86      4522\n",
            "   macro avg       0.68      0.71      0.69      4522\n",
            "weighted avg       0.87      0.86      0.86      4522\n",
            "\n",
            "-------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}